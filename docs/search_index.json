[["intro.html", "Chapter 1 API 1.1 Local Database Option 1.2 Your Token 1.3 R script: api_run.R 1.4 Terminal 1.5 Data Cleaning 1.6 Incorporating Node Data Into Your Database", " Chapter 1 API 1.1 Local Database Option This makes sense for a single project, so specify which of your CTT projects will be loaded into the database with the “myproject” option set to the project name on your account. (To look up your project name by station, go to “My Stations” on your account and click on the station of interest to see which project it’s affiliated with.) If you choose to create a database out of your data (fair warning: in the future, the analysis tools will be based on this structure) you will need to install PostgreSQL on your machine. Disclaimer I am providing some basic instructions for getting setup with Postgres on Windows and creating a user and database here, but please use at your own discretion and do not contact me with Postgres install questions. If any of these steps fail, seek another tutorial for installing Postgres and cross-reference with the steps here. [Download and install] (https://www.postgresql.org/download/) for your OS If pgAdmin wasn’t installed with your PostgreSQL installation, it’s a nice GUI for interacting with and visualizing your database For simplicity, create a Postgres user with the same name as your computer user name. Otherwise, you will need to pass it as an argument to the connection Create a database in Postgres owned by that user name. You may have to set a password, and you may have to pass that password as an argument to the connection you may need to update your pg_hba.conf file to use the “trust” method for your connections if so, you’ll also need to reload the configuration/restart Postgres for the new settings to take Creating a Postgres database through the API includes the following data checks &amp; structures: attempt to correct files missing headers removal of bad time records (bounded by station deployment dates) beep data file the beep came from attached to the record unique id for each beep record filtering: removal of records without… radio id time stamp node health re-coding battery &gt; 9 to NA filtering: removal of records without… unique combination of radio id, node id, time and station id kept (i.e. removal of duplicates) time stamp In development: salvaging corrupt rows where possible tag ID validation 1.2 Your Token Please request an API token through this form. The token will appear on your account page when the request is fulfilled. 1.3 R script: api_run.R Assign the API token you found above to the “my_token” variable Set your “outpath” variable to wherever your files will live. If you have already been manually downloading files, use that as your “outpath.” The script will search that directory, and will only download files you haven’t already downloaded. It will create a nested folder structure within that directory in the following order: project name, station(s), file types, files If you do not want to create a database… do not set the “conn” variable remove the “conn” argument from the get_my_data() function do not run update_db() comment out the dbDisconnect() line If you do want to create a database locally, set “db_name” to the name of the Postgres database you created An example script using the API tools to download files: library(celltracktech) library(DBI) start &lt;- Sys.time() ####SETTINGS##### my_token &lt;- &quot;your token here&quot; db_name &lt;- &quot;mydb&quot; myproject &lt;- &quot;CTT Project Name&quot; #this is your project name on your CTT account conn &lt;- dbConnect(RPostgres::Postgres(), dbname=db_name) ################ outpath &lt;- &quot;~/Documents/data/radio_projects/myproject&quot; #where your downloaded files are to go get_my_data(my_token, &quot;~/Documents/data/radio_projects/myproject&quot;, conn, myproject=myproject) update_db(conn, outpath, myproject) dbDisconnect(conn) #findfiles(outpath, &quot;directory path where you want your caught files to go&quot;) time_elapse &lt;- Sys.time() - start print(time_elapse) 1.4 Terminal Run “Rscript &lt;path to your copy of api_run.R&gt;” on the command line to run the script outside of RStudio (recommended) 1.5 Data Cleaning To remove duplicate records from your database (more than one record that has the same time stamp of a tag ID “beeping” on a node) the db_cleanup() function may be used. Additionally, if there are erroneous records of the same time stamp, tag ID and node ID with varying RSSI values, all records for that “beep” (combination of timestamp, tag ID and node ID) will be removed. 1.6 Incorporating Node Data Into Your Database To include data pulled from your node SD card(s) create a folder called “nodes” and populate it with folders named for each node. Place the data pulled from each node in its respective folder. If you have already pulled sensor station data via the API, place the “nodes” folder in the folder that is auto-created by get_my_data() named for your project. In this case, the “outpath” and “myproject” arguments remain the same as for the functions above. In absence of a project name, “outpath” will be the folder containing the “nodes” folder. Run import_node_data(conn, outpath, myproject=\"your project name\") to read in your node data and add it to the database such that it will not duplicate sensor station data. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
